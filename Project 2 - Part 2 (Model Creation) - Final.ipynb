{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NIUjBK2Ix1FX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIUjBK2Ix1FX",
    "outputId": "91b26f80-1472-4ed8-f88c-3199d2d0823b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, driver_version, memory.total [MiB]\n",
      "Tesla P100, 460.32.03, 11441 MiB\n"
     ]
    }
   ],
   "source": [
    "# We are using COLAB as it gives us access to a much faster gpu\n",
    "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv\n",
    "# Tesla P100, a $5,699 gpu!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mo5t3We8xVdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Mo5t3We8xVdc",
    "outputId": "58672fdd-ce03-47cf-e409-5ea7d1827e1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-fcf7477e-d8a4-4ecc-a77f-39f526e0d808\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-fcf7477e-d8a4-4ecc-a77f-39f526e0d808\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"finleysmith\",\"key\":\"e680faf4a906c1241f6a06c82de84d47\"}'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code as per Kaggle instructions to enable colab\n",
    "# Much faster to download data using google's internet than uploading from mine\n",
    "\n",
    "!pip install -q kaggle\n",
    "\n",
    "from google.colab import files \n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4BA_zsv7xezc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BA_zsv7xezc",
    "outputId": "469ea88d-b24c-49df-c25a-9e3c42c42f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "-rw------- 1 root root   67 Apr  7 17:07 kaggle.json\n",
      "drwx------ 1 root root 4096 Apr  7 17:08 ..\n",
      "drwxr-xr-x 2 root root 4096 Apr  7 17:08 .\n",
      "Downloading ieee-fraud-detection.zip to /content\n",
      " 95% 112M/118M [00:00<00:00, 151MB/s] \n",
      "100% 118M/118M [00:00<00:00, 143MB/s]\n",
      "Archive:  data/ieee-fraud-detection.zip\n",
      "  inflating: data/sample_submission.csv  \n",
      "  inflating: data/test_identity.csv  \n",
      "  inflating: data/test_transaction.csv  \n",
      "  inflating: data/train_identity.csv  \n",
      "  inflating: data/train_transaction.csv  \n"
     ]
    }
   ],
   "source": [
    "# Following the guide given here https://www.kaggle.com/general/74235\n",
    "!mkdir  -p /root/.kaggle/\n",
    "!mv kaggle.json  /root/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "!ls -lart /root/.kaggle/\n",
    "!kaggle competitions download -c 'ieee-fraud-detection'\n",
    "!mkdir data\n",
    "!mv ieee-fraud-detection.zip data/\n",
    "!unzip data/ieee-fraud-detection.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47f781a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "f47f781a",
    "outputId": "0516a1f1-3911-419d-997b-e03c05137804"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Import our libs etc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os,gc,re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc,confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Import the files from data directory\n",
    "train_transaction, test_transaction = pd.read_csv('data/train_transaction.csv'), pd.read_csv('data/test_transaction.csv')\n",
    "train_identity, test_identity = pd.read_csv('data/train_identity.csv'), pd.read_csv('data/test_identity.csv')\n",
    "\n",
    "# We notice that some of the columns for test and train identity are miss-named using - instead of _ so we will correct\n",
    "test_identity.columns = [col.replace(\"-\",\"_\") for col in test_identity.columns]\n",
    "\n",
    "\n",
    "# Merge the transaction and identity types\n",
    "df_train = train_transaction.merge(train_identity, on = ['TransactionID'], how = 'left')\n",
    "df_test = test_transaction.merge(test_identity, on = ['TransactionID'], how = 'left')\n",
    "\n",
    "del train_transaction, train_identity, test_transaction, test_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8913dea",
   "metadata": {
    "id": "f8913dea"
   },
   "outputs": [],
   "source": [
    "# Lets ensure we are using the right types\n",
    "# column details\n",
    "cat_cols = (['ProductCD'] + ['card%d' % i for i in range(1, 7)] + ['addr1', 'addr2', 'P_emaildomain', 'R_emaildomain'] + \n",
    "            ['M%d' % i for i in range(1, 10)] + ['DeviceType', 'DeviceInfo'] + ['id_%d' % i for i in range(12, 39)])\n",
    "\n",
    "# Make them all strings for now\n",
    "type_map = {c: str for c in cat_cols}\n",
    "df_train[cat_cols] = df_train[cat_cols].astype(type_map, copy=False)\n",
    "df_test[cat_cols] = df_test[cat_cols].astype(type_map, copy=False)\n",
    "id_cols = ['TransactionID', 'TransactionDT']\n",
    "\n",
    "# Create a list of all the numeric columns\n",
    "numeric_cols = (['TransactionAmt', 'dist1', 'dist2'] + ['C%d' % i for i in range(1, 15)] +\n",
    "                  ['D%d' % i for i in range(1, 16)] + ['V%d' % i for i in range(1, 340)] + ['id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', \n",
    "    'id_09', 'id_10', 'id_11'])\n",
    "\n",
    "# Taken from our EDA notebook (Part 1), we list all the v-values we want\n",
    "v_cols = ['V1', 'V3', 'V4', 'V6', 'V8', 'V11', 'V13', 'V14', 'V17', 'V20', \n",
    " 'V23', 'V26', 'V27', 'V30', 'V36', 'V37', 'V40', 'V41', 'V44', 'V47', 'V48', 'V54', 'V56', 'V59', \n",
    " 'V62', 'V65', 'V67', 'V68', 'V70', 'V76', 'V78', 'V80', 'V82', 'V86', 'V88', 'V89', 'V91', 'V96', \n",
    " 'V98', 'V99', 'V104', 'V107', 'V108', 'V111', 'V115', 'V117', 'V120', 'V121', 'V123', 'V124', 'V127', \n",
    " 'V129', 'V130', 'V136', 'V138', 'V139', 'V142', 'V147', 'V156', 'V162', 'V165', 'V160', 'V166', 'V178',\n",
    " 'V176', 'V173', 'V182', 'V187', 'V203', 'V205', 'V207', 'V215', 'V169', 'V171', 'V175', 'V180', 'V185', \n",
    " 'V188', 'V198', 'V210', 'V209', 'V218', 'V223', 'V224', 'V226', 'V228', 'V229', 'V235', 'V240', 'V258', \n",
    " 'V257', 'V253', 'V252', 'V260', 'V261', 'V264', 'V266', 'V267', 'V274', 'V277', 'V220', 'V221', 'V234', \n",
    " 'V238', 'V250', 'V271', 'V294', 'V284', 'V285', 'V286', 'V291',\n",
    " 'V297', 'V303', 'V305', 'V307', 'V309', 'V310', 'V320', 'V281', 'V283', 'V289', 'V296', 'V301', 'V314', 'V332', 'V325', 'V335', 'V338']\n",
    "\n",
    "# Create a list of v columns we want to DROP\n",
    "drop_cols = [col for col in df_train.columns if col[0] == 'V' and col not in v_cols]\n",
    "\n",
    "# Get rid of the columns we need to drop\n",
    "df_train = df_train.drop(columns=drop_cols)\n",
    "df_test = df_test.drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1238fc0f",
   "metadata": {
    "id": "1238fc0f"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "#  Adding the day and hour\n",
    "df_train['day'] = (df_train['TransactionDT']//(60*60*24)-1)%7\n",
    "df_test['day'] = (df_test['TransactionDT']//(60*60*24)-1)%7\n",
    "\n",
    "df_train['hour'] = (df_train['TransactionDT']//(60*60))%24\n",
    "df_test['hour'] = (df_test['TransactionDT']//(60*60))%24\n",
    "\n",
    "# Adding the amount after decimal for transaction amount\n",
    "df_train['TransactionAmtDecimal'] = (df_train['TransactionAmt'] - np.floor(df_train['TransactionAmt'])).astype('float32')\n",
    "df_test['TransactionAmtDecimal'] = (df_test['TransactionAmt'] - np.floor(df_test['TransactionAmt'])).astype('float32')\n",
    "\n",
    "# We could try adding more features, but in early testing they were not effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0630faa",
   "metadata": {
    "id": "a0630faa"
   },
   "outputs": [],
   "source": [
    "# First setup our X and Y data sets\n",
    "\n",
    "y_train = df_train['isFraud'].copy()\n",
    "\n",
    "X_train = df_train.drop('isFraud', axis = 1)\n",
    "X_test = df_test.copy()\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "# Fill our na values with a number that xgboost will recongise as NA\n",
    "X_train = X_train.fillna(-999)\n",
    "X_test = X_test.fillna(-999)\n",
    "\n",
    "# Label Encoding to convert the objects and caterogies into numeric, using our previous lists\n",
    "# to assist with finding the correct type\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].dtype=='object' or X_test[i].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(X_train[i].values) + list(X_test[i].values))\n",
    "        X_train[i] = lbl.transform(list(X_train[i].values))\n",
    "        X_test[i] = lbl.transform(list(X_test[i].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "zQjmFyvrY63y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQjmFyvrY63y",
    "outputId": "4386590b-30ee-4c89-bf52-4e76b461dfa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
	{
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints...\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.4, 0.8],\n",
       "                                        'learning_rate': [0.002, 0.01, 0.02,\n",
       "                                                          0.1, 0.2],\n",
       "                                        'max_depth': [6, 12],\n",
       "                                        'n_estimators': [2000, 5000],\n",
       "                                        'subsample': [0.4, 0.6, 0.8],\n",
       "                                        'tree_method': ['hist']},\n",
       "                   random_state=12, refit=False, scoring='roc_auc', verbose=20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start up XGBoost\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "# Create a grid of parameters we want to learn over\n",
    "param_grid = {\n",
    "    'max_depth': [6, 12],\n",
    "    'learning_rate': [0.002, 0.01, 0.02, 0.1, 0.2],\n",
    "    'subsample': [0.4, 0.6, 0.8],\n",
    "    'colsample_bytree': [0.4, 0.8],\n",
    "    'n_estimators': [2000, 5000],\n",
    "    'tree_method':['gpu_hist']}\n",
    "\n",
    "# Use randomisedsearchcv to efficently tune our hyper-parameters\n",
    "rs_clf = RandomizedSearchCV(clf, param_grid, n_iter = 5, n_jobs = -1, verbose= 20, cv = 3, scoring='roc_auc',\n",
    "                            refit=False, random_state = 12)\n",
    "\n",
    "# Bind the search to our data\n",
    "rs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95e16ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_method': 'hist',\n",
       " 'subsample': 0.8,\n",
       " 'n_estimators': 5000,\n",
       " 'max_depth': 12,\n",
       " 'learning_rate': 0.02,\n",
       " 'colsample_bytree': 0.4}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best parameters to use\n",
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f4eabe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "f3f4eabe",
    "outputId": "6338c539-cd00-4721-92d2-bac64c27d427"
   },
   "outputs": [],
   "source": [
    "# Create our parameters for our XGBOOST model\n",
    "# We make sure to enable the GPU to run much fuster on colab\n",
    "# We use the parameters from the RandomisedSearchCV above\n",
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=5000,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.02,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.4,\n",
    "    missing=-999, # As above this is our na number\n",
    "    random_state=2471, # Last 4 digits of matric\n",
    "    eval_metric=[\"error\", \"auc\"],\n",
    "    tree_method='gpu_hist'  # Enable google's expensive gpu\n",
    ")\n",
    "\n",
    "# Fit the model to our training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ff11cf",
   "metadata": {
    "id": "22ff11cf"
   },
   "outputs": [],
   "source": [
    "# Create the sumbission for Kaggle\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='TransactionID')\n",
    "sample_submission['isFraud'] = clf.predict_proba(X_test)[:,1]\n",
    "sample_submission.to_csv('simple_xgboost.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Finley Smith - Project 2 - Feature Encoding and Modelling].ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
